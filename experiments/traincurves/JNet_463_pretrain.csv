training loss,validatation loss
0.1373219683393836,0.1331569604575634
0.1130576959811151,0.1340813733637333
0.11066025657579302,0.13165677301585674
0.10834885952994228,0.11923265233635902
0.1077755444124341,0.10845575779676438
0.10662534013390541,0.11590027213096618
0.09897689800709486,0.10884774141013623
0.097655108878389,0.12074834369122982
0.09645597081631423,0.11349976062774658
0.09398488162085414,0.09240062199532986
0.09362950683571399,0.09960203655064107
0.08894110205583275,0.0997896920889616
0.09168885435909033,0.10642920732498169
0.08813847091048956,0.10105429161339999
0.08712389154359698,0.08814810831099748
0.08426923923194408,0.10152573548257351
0.08515593324787915,0.07956756204366684
0.08144021209329366,0.10444935448467732
0.08448561755940318,0.10592472050338983
0.07428479150868952,0.08393222223967314
0.07007700338028372,0.0903796549886465
0.07059062371961772,0.07967160306870938
0.06997695391066372,0.08218211513012648
0.06601764600723982,0.0815308092162013
0.0641483654640615,0.08226146213710309
0.0673091038968414,0.08198783192783594
0.06792841656133533,0.08390888813883066
0.0668731991108507,0.08467832803726197
0.06129354814067483,0.08373094853013754
0.06339359690435231,0.07756804805248976
0.06703517409972846,0.07945471871644258
0.06482923600822688,0.08171546924859285
0.06308773532509804,0.08114915043115616
0.06727054250426591,0.08412291277199983
0.06592840899713337,0.0694781132042408
0.06159453767351806,0.07648390978574753
0.06208466704003513,0.073223870806396
0.06406233066692948,0.08052619230002164
0.06351358676329255,0.07569897156208753
0.06215017532929778,0.07876617684960366
0.06411076870746911,0.08037160746753216
0.06559417251497507,0.0852448983117938
0.06577344092540444,0.08653894420713186
0.0686800351832062,0.07285852581262589
0.06191232142969966,0.07619913332164288
0.06488257265649736,0.08255760315805674
0.06639552819542587,0.06936641167849303
0.064281942602247,0.08667163755744696
0.06144101954996586,0.07359571009874344
