training loss,validatation loss
0.13812919206917285,0.26258250772953035
0.11332669364288449,0.11923851408064365
0.10152181854471565,0.13112310953438283
0.09629019787535072,0.10581379160284995
0.09901582865975797,0.09777001701295376
0.09325152618810534,0.09986743237823248
0.08719693807885051,0.08673131950199604
0.09131013170816005,0.0877939660102129
0.09097595588304103,0.08419624082744122
0.0872151845972985,0.08160102758556605
0.07981874999590217,0.0882266553118825
0.08217264315113425,0.09770070649683475
0.08369364658370614,0.08526827674359083
0.08053013743832707,0.07745147719979287
0.07769204230047762,0.09260257091373206
0.07692508962936699,0.07343212105333805
0.0774200648535043,0.0770092586055398
0.07407239519990981,0.07923020981252193
0.06812541561201214,0.08191249873489141
0.06779190574772656,0.07292890790849924
0.0666139330714941,0.08203544709831476
0.0674475362803787,0.07955374997109174
0.0671185361687094,0.08412851449102163
0.065584675995633,0.08317169342190027
0.06708220100495964,0.08886388633400202
0.0658478473033756,0.07546844780445099
0.06430075647309423,0.08625538758933544
0.06665961792692542,0.09515401087701321
0.06372997864149511,0.08374257199466228
0.065247014882043,0.08801269493997096
0.06507931598462165,0.08044212628155947
0.06514928096905351,0.08637117072939873
0.06550437648780644,0.08102130126208067
0.0636959514953196,0.08927304968237877
0.06336433963850141,0.082027468085289
0.06239524310454726,0.07895238772034645
0.06562935241498052,0.08210104797035456
0.05954560339450836,0.07509269304573536
0.06537735505960882,0.09198314789682627
0.06730859287083149,0.08550734035670757
0.061005436591804026,0.07310358807444572
0.06985220639966429,0.0755803283303976
0.06744624288752675,0.08131325971335172
