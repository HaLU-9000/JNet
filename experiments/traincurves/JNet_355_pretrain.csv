training loss,validatation loss
0.1414021156169474,0.23909557685256005
0.11556203601881862,0.15969025418162347
0.11350879007950425,0.12732455730438233
0.10946370093151928,0.11822477579116822
0.10391963623464108,0.09851441495120525
0.09956802109256387,0.1111940935254097
0.10361719051375985,0.11890628878027201
0.10170409554615617,0.10556974411010742
0.09479558187536895,0.09437826573848725
0.09113347534090281,0.0881366765126586
0.09699463667348027,0.1010750237852335
0.08975041817873716,0.09825103320181369
0.08961747096851468,0.10068094320595264
0.08886555773206055,0.09479187428951263
0.08534273639321327,0.0950627077370882
0.08392715658061206,0.0897824652493
0.08443243727087975,0.09765400625765323
0.08090231920592487,0.1026586003601551
0.07918632143177091,0.09867633990943432
0.08036935153417289,0.10953923799097538
0.0796586082316935,0.0936765767633915
0.07890000398270786,0.10552648268640041
0.0765594584029168,0.10753079839050769
0.07224019447341562,0.11428484469652175
0.07364873577840626,0.10388132091611624
0.0684591322299093,0.11267800144851207
0.07514403910376131,0.10831908881664276
0.07099803037010133,0.10075746942311525
0.07571068259887398,0.09570329822599888
0.07240744172595441,0.10436425246298313
0.07533101513981819,0.08706748820841312
0.06744558102451265,0.10464638620615005
0.07007796755991876,0.08970060963183642
0.07391226765699685,0.0988432252779603
0.06754478660412133,0.09233224373310804
0.07068751007318497,0.1114123310893774
0.07010628283955157,0.10927946399897337
0.07111178748309613,0.12366637997329236
