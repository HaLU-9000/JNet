training loss,validatation loss
0.0008912995381547262,0.0005318372812940453
0.000530500823988973,0.00024396755911908484
0.0003021085935409928,0.00019752229314771164
0.00023651638281016574,0.00012925314390986026
0.00017464751912797284,0.00028753691349786575
0.00020572069912304868,0.0003284897427483169
0.00021272901977425817,0.0003345396790990662
0.0002290603382647305,0.00027793874289159246
0.00016567989527089823,0.00014287706965276925
0.00017215083440802915,9.694636393504652e-05
0.00021146763490150988,0.00013269562583957396
0.00018852835685777335,0.0003472940583833406
0.004181981100510796,0.004811277793965019
0.004552402953939065,0.003532930594650452
0.004974927283885506,0.0052871786080942226
0.00496120452934548,0.004589300568449061
0.004106236593806045,0.003003134716908562
0.004673680695455005,0.00812489765492046
0.004867747496729607,0.0045234161216484384
0.004482568616280958,0.0056881117292704175
0.00535683010371514,0.0050590043912052355
