training loss,validatation loss
0.13378749538213014,0.1153894908260554
0.06354567215312272,0.07837990475818515
0.052911447938531635,0.0755989208817482
0.04811584087088704,0.06220176410861313
0.0449720799876377,0.06685589188709855
0.04444918498862535,0.10724465949460864
0.0419355355668813,0.06098186448216438
0.048442354956641794,0.06943748095072806
0.04366806182079017,0.05069194328971207
0.041015798333100977,0.051943708257749674
0.03662702796282247,0.05116493166424334
0.04017752116080373,0.04735505152493715
0.03728264542296529,0.04600155563093722
0.037951329578645526,0.04456455633044243
0.038504913221113386,0.04445057874545455
0.03282729917671531,0.04113436387851834
0.032956963253673165,0.037865850422531364
0.028849129823502153,0.034994402527809144
0.03328339148778468,0.035044044838286936
0.02970128110377118,0.03499501312617213
0.028379990542307495,0.035433035576716065
0.03097178558818996,0.034744929242879155
0.030314019657671453,0.03500558822415769
0.028931101674679667,0.03552105696871877
0.02662131644319743,0.03443048915360123
0.02875777111388743,0.03419352234341204
0.029726357229519634,0.03359015863388777
0.028081576018594206,0.03371271276846528
0.028545524142682552,0.033991171745583415
0.03046166674233973,0.034261561930179596
0.031169327560346575,0.03380958798807114
0.02918760363245383,0.03375935556832701
0.02848797384882346,0.03447003916371614
0.028184432123089208,0.03391007503960282
0.027892954577691854,0.03425147838424891
0.030193592864088716,0.03441815031692386
0.028445389594417066,0.03412586993072182
0.029958933920133858,0.033733358280733226
0.027487382274121046,0.03383554462343454
0.027176079594064505,0.03426923281513154
0.029897090904414655,0.0338013966800645
