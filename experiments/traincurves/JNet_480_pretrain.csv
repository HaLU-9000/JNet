training loss,validatation loss
0.11683924178592861,0.10853385496884585
0.05790925591252744,0.08969460921362042
0.04524140649475157,0.06285765925422311
0.04043366823345423,0.0593907012604177
0.046745383678935465,0.06248706988990307
0.038997312404680996,0.05084788240492344
0.039719961429946125,0.052594084991142154
0.037842159741558135,0.04151494093239307
0.03166858848417178,0.04517662860453129
0.038670299428049476,0.03667320343665779
0.03290302069624886,0.047041712887585165
0.03753000498982147,0.04033007211983204
0.03328646905953064,0.039286918379366396
0.034494178872555493,0.037082589231431484
0.03132487088209018,0.044415238127112386
0.03201513542793691,0.03524958584457636
0.0322851472068578,0.04490648163482547
0.029332429927308112,0.03501185814384371
0.02848979810019955,0.03492082417942584
0.027719771491829307,0.03437780337408185
0.028514784995932133,0.03300330634228885
0.025532618458382787,0.03397984157782048
0.02620992763200775,0.033437075186520816
0.025611316135618834,0.03417359155137092
0.025700324106728657,0.03210079011041671
0.02664261108497158,0.03254005352500826
0.026208302420563996,0.035563755431212485
0.026033824905753136,0.03199050377588719
0.024916718101594598,0.032540837908163665
0.025089553836733103,0.03219241481274367
0.02591035742778331,0.03241632878780365
0.023728026065509767,0.03178370154928416
0.025408960247877987,0.03206422429066151
0.026857247076695786,0.03198172643315047
0.024938603537157177,0.033575738966465
0.025687536916229874,0.032934738183394076
0.026446291413158178,0.035875799623318015
0.025230489454697816,0.03288239492103458
0.023562439295928925,0.03318796737585217
0.024615177344530823,0.03227329787332565
0.026460704389028252,0.032177223823964596
0.026655588673893362,0.03415310969576239
0.02663418559823185,0.03254078961908817
0.027348654023371638,0.033048176346346735
