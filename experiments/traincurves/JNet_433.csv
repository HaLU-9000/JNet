training loss,validatation loss
0.0009748623002951717,0.0011253192776570665
0.0006296559264137614,0.00039875917371714304
0.0003989068710552601,0.00026023888176585346
0.0002538588778111261,0.0003406897181210446
0.00025576549775450984,0.0002779147253932024
0.00023947194336415123,0.00018001237313001184
0.00019931019837713393,0.00011070571840718913
0.00023035479350596688,0.0006617270292622379
0.0002532958976377131,0.00023266472063596667
0.00022427619355028128,0.00022067902691560448
0.0002501997402140432,0.0002060269221544786
0.00022964892683773996,0.00024533782437856643
0.00021720330895334429,0.00014198626028587568
0.00020527252639936932,0.0003605350123507378
0.00023641284537745833,0.00013327434356540379
0.00020235923818603396,0.0001589154571860263
0.0001990838763911995,0.0002570232733035027
0.00021166908099274907,0.0005725231496469974
0.00021040268007169516,0.00015692474723891792
0.00018328691762292237,0.0013693127079818623
0.00019786719948399422,0.00083911590482586
0.0002275566066643364,0.00023034364367617853
0.0001978369527732582,0.0011756380086296759
0.00021983778740263915,0.00019491000904849897
0.00019223484922491706,0.00024250769833145114
0.0002487645144132955,0.0003078246204154311
