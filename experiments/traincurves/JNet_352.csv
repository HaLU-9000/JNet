training loss,validatation loss
0.0007921846028330037,8.834985869725643e-05
0.00029071801781356045,0.0001510748226337455
0.0002869627253676299,0.00012871620040186827
0.00023235245786963786,0.00010794423740208003
0.0002440748583376262,0.00017139771134679904
0.00025496991461295695,0.00011622803724549158
0.0002953323381643713,0.00015092931443518864
0.00022714004073350223,8.078588214175398e-05
0.0002600884155344829,9.989728215487048e-05
0.00022252279235544846,0.00011764715933395564
0.00021586513520560402,0.00010525856805259082
0.0002292141691032157,9.361566265795319e-05
0.0002341987483032426,0.00010585067599464538
0.0002076807687717519,9.495174948597196e-05
0.00024426065159786957,8.910045461902882e-05
0.00022099841874478443,0.00011927195708949512
0.0002553288787657948,8.238080514004764e-05
0.0002065331180801877,9.472313989249415e-05
0.00020851770028457395,0.00012189587133661916
0.0002701317554419802,0.00011165415264287048
0.00023929529716951948,0.00010867634706528407
