training loss,validatation loss
0.0005162768170248455,9.074434724425373e-05
0.00028118380628257,0.00010521651329327142
0.00027716840986613533,0.00010536402742235408
0.0002630406048956502,8.001174478522444e-05
0.0002505104201281938,0.00010202117542803534
0.0002529283734111232,9.992602383590565e-05
0.0002404219789787021,0.0001376231959739016
0.0002221801970972592,9.021150913213205e-05
0.00019508650389980176,0.00010637292324418013
0.0002045776379236486,9.505097876285617e-05
0.00022107619972302928,0.00010467723296869735
0.0002247668140444148,0.00010306983450618646
0.00023218421554702218,9.669312422317944e-05
0.00019170039406162686,9.410664994220496e-05
0.00022198935939741205,9.26029348818247e-05
0.00021383738530857954,0.00010210785758317798
0.0002106978170650109,8.552017560532476e-05
0.0002810407852120989,8.356194579164366e-05
0.00022811014267972495,0.00010665223740318197
0.00020385063852700112,0.00011154657109955224
0.0001985372571652988,0.00011843961409852
