training loss,validatation loss
0.0004470654320334688,0.00024230255370480958
0.0003284743776606547,0.00026082682049895385
0.00025305169943095506,0.0002877486941165304
0.00020133903734702584,0.00012658868274932898
0.00022079091763515634,0.00016925398936366382
0.0001907013316028383,0.0002739012876588824
0.00023339703188099748,0.001267340252538696
0.00021547191881694517,0.00022157221780503278
0.00018980886127181406,0.00017883728430376778
0.00018995102895544847,0.00015409044688965423
0.00018875852651603964,0.0001759001644188629
0.0002115827047251173,0.00019190638628003854
0.00018831482032013013,0.00035272102801684466
0.00026705550777506915,0.00048203158603996597
0.00020295400989340352,0.0002063591925690389
0.00015825572122281527,4.613432379017013e-05
0.00021689930389186428,7.01321600558913e-05
0.00021488749207890123,0.0001533163518288916
0.00020527895275193942,0.0001403781713747776
0.00017418940219670275,0.00019189288680081517
0.0001424956175260661,0.000489838223388972
0.0002058825691688071,0.00046888898048678127
0.0001658438912285476,0.0005226004362384629
0.00017664476969883936,0.00020333129662617467
0.00016270589096791354,0.0002562704509756486
0.00016009930215730607,0.00017576328631321302
0.0001923687164793364,0.00023398042735607306
0.00020617044904213343,0.0002977027800227461
0.0001811868714210618,0.00020785865014261162
0.00019362853349903732,0.0004735363519955627
