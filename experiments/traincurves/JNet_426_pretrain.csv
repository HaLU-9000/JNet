training loss,validatation loss
0.14024424619972706,0.23156042769551277
0.1163853974826634,0.12076543420553207
0.11678497696295381,0.12135041989386082
0.10947581546381116,0.12027105540037156
0.10246800133958459,0.0995753113180399
0.09610128588974476,0.10849979296326637
0.10114248018711805,0.11307297460734844
0.10082340342923998,0.10077378377318383
0.0986584653519094,0.0900715734809637
0.0958735991641879,0.09849343448877335
0.09759026674553752,0.09860032014548778
0.0916487461514771,0.10679443031549454
0.09091930851340294,0.09784224331378936
0.08615205300971866,0.09237060882151127
0.08926825176924467,0.07966360244899988
0.08771285179071128,0.083660301938653
0.08431169329211116,0.09201883748173714
0.08407877650111914,0.10390477627515793
0.07807291388511657,0.08965814877301455
0.07367359078489244,0.08679681047797203
0.07505158619023859,0.08185312189161778
0.07759119594469667,0.07862982768565416
0.07969090756960213,0.09409987647086382
0.07319963018409908,0.08937924765050412
0.07585206234827638,0.08376076836138964
0.07937636104412377,0.07562879659235477
0.07437520656734704,0.08321570158004761
0.07302310790866613,0.07910315413028002
0.0753535527922213,0.07968455366790295
0.07339379159733653,0.10346827432513236
0.07726951313205063,0.08324227221310139
0.07229252003133296,0.09584630131721497
0.07329450343735516,0.08251438662409782
0.07780782854184508,0.07898458559066057
0.07729227758012712,0.0883985262364149
0.07391101923771203,0.08345969952642918
0.07349854594096542,0.10148154832422733
0.07429493258707226,0.08787836469709873
0.07483912719413638,0.08974677249789238
0.07791198548860848,0.07917319163680077
