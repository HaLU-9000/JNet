training loss,validatation loss
0.1431929822638631,0.14361901469528676
0.10677482148632407,0.14061902612447738
0.10729117978364229,0.10618919041007757
0.10540945300832391,0.11964724659919738
0.09666048457846045,0.10168929230421782
0.09540712788701057,0.11322131045162678
0.09285998702049256,0.09100404642522335
0.09134098066017032,0.12013130933046341
0.08819236095063389,0.0895724780857563
0.08181810081936419,0.09364577028900385
0.08131034625694156,0.08583319317549468
0.08177153683267534,0.08977934326976537
0.07799747983925044,0.10604996271431447
0.08095046050846577,0.07809350229799747
0.07416389370337129,0.08024231810122728
0.08013525302521884,0.08761124070733786
0.07628185788169503,0.07411923259496689
0.06827400861307979,0.09436594620347023
0.07458690097555518,0.09698223769664764
0.06361014500260354,0.08125771321356297
0.06616524948738516,0.08205700479447842
0.06537706303410232,0.07866595778614283
0.06491645607165993,0.09627361856400966
0.06266644109971821,0.09592509511858224
0.06306380619294942,0.07985917199403048
0.06225108677521348,0.09013204649090767
0.06170110719278455,0.08780347015708685
0.06479158013127745,0.08761419728398323
0.06214385855011642,0.07864738460630179
0.060519594419747594,0.0903470542281866
0.059948039185255764,0.08152051344513893
0.06052475751843303,0.09392101876437664
0.06194078321103007,0.07503976318985224
0.06115077693015337,0.07517241183668374
0.06090151567012072,0.07437275070697069
0.06208297995850444,0.08348974343389273
0.0616325892880559,0.08899807818233967
0.06084694772493094,0.09173765722662211
0.06156919711269438,0.0895757220685482
0.059342378163710234,0.08240216560661792
0.060078485747799275,0.08229872286319732
0.06117329567670822,0.08964298684149981
0.060889599332585934,0.08160403072834015
