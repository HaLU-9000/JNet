training loss,validatation loss
0.0006729794843886339,0.00011150597911197385
0.0003615285224077525,0.00014981751373852604
0.0002983580982345302,9.213742935116897e-05
0.0002704899532091076,0.00010772470258757494
0.0002896524073821638,8.831418434454008e-05
0.00023999089799872308,0.0001240501414542905
0.00029054741837171606,9.624604542040061e-05
0.0002717643868163577,0.00010614382674702937
0.0002516928883505898,0.00013703773787483443
0.0002431201341551059,0.00011364686703529969
0.0002130053797918663,0.00012616180717657245
0.0002904627338921273,0.00010994610327088594
0.00034465946336240447,0.00018796593220145042
0.0002646794543852593,0.00011326179869683984
0.00022511849803777295,0.00012082790090630623
0.0003059049565308669,0.00013175940583778356
0.0002275554961124726,0.00011075193139333805
0.0002234441850305302,0.0001324755385098797
0.00021340712346500367,0.00010351038838791737
0.00021481620134181868,0.0001291330205731356
0.00027661588042064976,0.00012715935742591
0.0002707672887572699,0.00010943162236571879
0.00025588818815776906,0.00011809976357923802
0.00021900514183471388,0.0001355644903739517
0.00023119390356441728,0.00010000764041535603
0.0002408130456569779,0.00012088931927962676
0.00022793537784309591,0.00010066790372036394
0.00022478608217170405,0.00010734420385176691
