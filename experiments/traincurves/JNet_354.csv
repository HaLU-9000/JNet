training loss,validatation loss
0.000706465498324178,8.49423754061725e-05
0.00036065524289369933,0.00010971221900035744
0.0003017552639812493,0.00010098049360749429
0.00027242643925546873,7.979834156230936e-05
0.00030753211417504643,9.399952559476787e-05
0.00025510513628432816,8.410919126049521e-05
0.00026089256841260066,8.381116509497133e-05
0.00024424181168797076,7.467774768770142e-05
0.00022949680722376799,0.00012879345753731287
0.00021000880720748683,8.36174138385104e-05
0.00021292625117894204,0.00010084131320695633
0.00022557766053068917,0.00012415022119682817
0.00026130983904295137,0.00012676459558633724
0.00025620330419769745,0.00010828787042100884
0.0002479572137235664,9.812407400886514e-05
0.00023985066451132298,0.00010661856796332359
0.00022875291940181342,9.992370477220902e-05
0.00021321456417354058,9.455936636868501e-05
0.00022407535594538787,0.00013530099710123977
0.00021593208964986843,0.00011700717713552357
0.00023827570293178725,0.0001298641644154941
0.00026932958603538283,0.00013832885386761974
0.00023081920386175625,9.801195458862822e-05
0.00021727226313487336,0.000126169226609818
0.00021809082250001666,0.00013491690353362173
0.00018753766697045647,0.00015273599933038896
0.00023493310196499807,0.00012132413075107706
0.00020799798153348092,8.810501182665575e-05
0.00022971212963966538,0.00010372149361614902
0.00018783001465635607,0.0001120878699595096
