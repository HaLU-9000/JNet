training loss,validatation loss
0.1295606200583279,0.16169894486665726
0.11110337474383414,0.16527583375573157
0.11176555342040956,0.08518567495048046
0.10397732964716852,0.08954208027571439
0.10488070264458656,0.09039272367954254
0.09553186266683042,0.08706173226237297
0.0994756490457803,0.09174082055687904
0.10323648083955049,0.07390607427805662
0.09715005812235177,0.07999964598566293
0.09897003562189638,0.08058926463127136
0.09990170694887639,0.07958328910171986
0.09316621095873416,0.08090391121804714
0.09448829398490488,0.08195519968867301
0.09142585951834917,0.07522350903600454
0.09149145360104739,0.0803877191618085
0.0880465184804052,0.07294647134840489
0.0854410935472697,0.07019487209618092
0.08113154854625464,0.06612533200532197
0.08569310656748712,0.07895201873034238
0.07975223129615187,0.06367102954536677
0.08117949702776968,0.06421010382473469
0.0801484722085297,0.06210209000855684
0.07979024772066623,0.0761556975543499
0.07852352714631707,0.0659918723627925
0.08135731738992036,0.060135208256542685
0.0766100416937843,0.0612305099144578
0.08153929790016264,0.06731050238013267
0.07691508444957434,0.0634983278810978
0.07953013648279011,0.060423803701996806
0.07806341816671193,0.07511918917298317
0.07960039032623172,0.06988553740084172
0.07773043627850712,0.06605580728501081
0.07738489386159926,0.06188176842406392
0.0781324080331251,0.06686210073530674
0.08137014260515571,0.06835568491369486
0.0749491080082953,0.07262151166796685
0.07739275552332402,0.07324084285646677
0.07362460503354669,0.06344296280294656
0.0825380661804229,0.05928960405290127
