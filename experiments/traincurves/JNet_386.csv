training loss,validatation loss
0.0010495596162968467,0.00011466565244724128
0.0006662485798483431,8.564636102242583e-05
0.0003536979774548854,0.00011159485104599307
0.0002470708858800208,5.1591672917528084e-05
0.00024109372590601198,5.1054058280897153e-05
0.0002094537935658991,6.594819167986543e-05
0.0002320976965359023,5.828673506584892e-05
0.00015497789097139501,6.254862729235811e-05
0.00015927895050992901,5.750987317583167e-05
0.00015685015234623734,4.55720210723598e-05
0.00016235382511126773,5.6621030867631814e-05
0.00029188005383048223,4.7654462377977325e-05
0.00016226862090150008,5.319507575239635e-05
0.00018580159384782747,5.60350893465511e-05
0.00013392487832504684,4.9339025270001e-05
0.00014999383408991206,5.014004380541337e-05
0.0001498397966616949,4.682327508334083e-05
0.0001162482896978645,4.78177788636458e-05
0.00013253875126594038,4.624565989530538e-05
0.0001236741279956277,4.7690077946072054e-05
0.00012180081349782767,4.517945604760598e-05
0.00012168550512654974,4.571178651531227e-05
