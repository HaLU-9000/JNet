training loss,validatation loss
0.24323791347444057,0.29215492233633994
0.23562686927616597,0.1898366093635559
0.22034516621381045,0.16999128721654416
0.20867509715259075,0.21098380014300347
0.2151081191934645,0.18439800143241883
0.1967323327064514,0.17410738170146942
0.20171422151848672,0.18146102055907248
0.19922626694664358,0.16227970607578754
0.2019086112268269,0.16615744940936567
0.18642551375553013,0.16075619533658028
0.172193350084126,0.17264435067772865
0.15830033358186482,0.14487605169415474
0.15881300770677625,0.15133160836994647
0.14601635470986365,0.12231638506054879
0.14433973177336157,0.14055458083748817
0.14467630349099636,0.13933078572154045
0.1394148829765618,0.11447188928723336
0.13702049198560418,0.11022276803851128
0.12269690997898579,0.11666597910225392
0.12783558030612766,0.11536618359386921
0.12464278362691403,0.11321777030825615
0.11848718875087798,0.11528193019330502
0.13032307726331055,0.10309280045330524
0.12003433185629547,0.11365811787545681
0.12518391794525086,0.1003495290875435
0.11881806130521,0.10360547881573438
0.12424085741862655,0.11123178228735923
0.1241294697765261,0.11192212887108326
0.12789652175270022,0.10161835961043834
0.1231944787595421,0.10142283588647842
0.12228606320917607,0.10264390408992767
0.12851831454783677,0.10868153832852841
0.12237579787150026,0.10878767929971218
0.12562414644286035,0.10480570420622826
0.12097230993211269,0.10881613567471504
0.1259749617241323,0.12345504127442837
0.12151935253292322,0.11016566008329391
0.12577816090546548,0.10491700880229474
0.12647066544741392,0.11137008741497993
0.12418302685953676,0.1031078688800335
0.12037529826164245,0.10704626813530922
0.12035901027731598,0.11773528009653092
0.12532178461551666,0.11703701410442591
