training loss,validatation loss
0.1178685482032597,0.15479066520929335
0.09430648479610682,0.14934294149279595
0.0897798265889287,0.0999083423987031
0.08694506600499154,0.09384821187704802
0.08467329874634742,0.098584945499897
0.09368087601847946,0.09575828537344933
0.08377870011143386,0.0786480538547039
0.08087332097813488,0.08295621480792761
0.07967105731368065,0.09816182181239128
0.07846088693477213,0.08733210675418376
0.08924140855669975,0.078893300332129
0.07304906011559069,0.06876457389444113
0.0761229753214866,0.08976218160241842
0.07611958992667496,0.08623798545449972
0.06988757343962788,0.083532053232193
0.0679301264602691,0.07563017513602972
0.07343150954693556,0.08044237792491912
0.06664872775785625,0.07713054846972227
0.06735492706298828,0.08403862286359072
0.060117784552276135,0.0731458779424429
0.05857955750077963,0.07468961142003536
0.05532357474323362,0.06315010208636522
0.05650779282674193,0.07258173730224371
0.05396929182112217,0.07735961247235537
0.0535231573227793,0.07870664950460196
0.0548062337283045,0.08039464373141528
0.05295127097517252,0.07765607181936503
0.05311427158303559,0.07755401879549026
0.05717086703050882,0.09110553059726953
0.05117148168385029,0.07885100785642862
0.05152943530119956,0.07604743111878634
0.04950095278210938,0.0823893453925848
0.0532564724329859,0.07111424300819635
0.051920968643389645,0.07161342576146126
0.05420972133986652,0.08525733444839716
0.05262366035021841,0.08136306274682284
0.05249532979913056,0.0780295254662633
0.05127363825216889,0.07476776372641325
0.053862461149692537,0.08892853781580926
0.05240367823280394,0.08855174034833908
0.053135933289304375,0.09945881199091673
0.05690818485338241,0.0690687395632267
0.05445121784228832,0.07513106651604176
0.052295295037329194,0.08504073098301887
0.05370490154251456,0.09051109906286
