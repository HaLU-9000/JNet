training loss,validatation loss
0.6687965515255928,0.6505570411682129
0.6383674150705337,0.6582495510578156
0.6327900862693787,0.6632541179656982
0.6290316775441169,0.6347743391990661
0.6262612718343735,0.6362754076719284
0.6228420367836952,0.6271867543458939
0.6227313786745071,0.6555686742067337
0.6245733588933945,0.6342911571264267
0.6215617117285729,0.6237667769193649
0.6210254970192909,0.62450130879879
0.6206561776995659,0.623796346783638
0.619085143506527,0.6221717298030853
0.6181425893306732,0.6269795805215835
0.6189652729034424,0.6234592467546463
0.6202876186370849,0.629421180486679
0.619136925637722,0.619041022658348
0.6173142528533936,0.6212776213884353
0.6169029095768929,0.6184745848178863
0.6170886576175689,0.6198520064353943
0.6153262501955032,0.6186206758022308
0.6168972483277321,0.619635871052742
0.6145562207698823,0.6167604178190231
0.6138111290335655,0.6156340152025223
0.6139531645178795,0.6154560327529908
0.6136320009827614,0.6153919607400894
0.6132567757368088,0.6155612528324127
0.6133174404501915,0.6151505917310714
0.6134852129220962,0.6149735271930694
0.6133405935764312,0.6148429542779923
0.6129500696063042,0.6150645434856414
0.6135066497325897,0.6147818982601165
0.6135198572278022,0.615068644285202
0.6129504519701005,0.6151284962892533
0.6129312279820442,0.6148203045129776
0.612554352581501,0.6148456543684006
0.6132680121064186,0.614891767501831
0.6126429799199105,0.6145430952310562
0.6129911291599274,0.6149602204561233
0.6139533349871635,0.6149230420589447
0.6128887638449669,0.6148317694664002
