training loss,validatation loss
0.15025746098253875,0.20089465603232384
0.11730712104588747,0.20362305250018836
0.1130339749995619,0.14649925902485847
0.11272716724313796,0.18082507839426398
0.11036686769220978,0.13456563106738031
0.10752339740283787,0.1331986550241709
0.10270166791975498,0.12676571300253273
0.10669501969590783,0.1249600789975375
0.1033325795456767,0.11778667848557234
0.10218687595799565,0.12328399177640677
0.10154604088515043,0.11943310294300317
0.09629971759393811,0.12043818049132823
0.09911641325801611,0.1207818171940744
0.09552316931076348,0.12433493724092841
0.08910148710943759,0.12451701099053025
0.08846909580752253,0.12901343228295445
0.10153318273834884,0.12811797456815838
0.09085267032496631,0.11419769092462957
0.08463682764675468,0.12606681808829306
0.09281798023264855,0.12353949584066867
0.08501891758292913,0.11117342300713062
0.08560603136196733,0.09639622066169977
0.07938040811568499,0.10854376768693327
0.07047448207158595,0.11262868181802332
0.07446891793981195,0.10972163886763156
0.07299961362034083,0.08937960830517114
0.07367201940156519,0.10451056668534875
0.07833157198503614,0.09505473454482853
0.0716474385606125,0.09724014750681817
0.07289752875920386,0.10572973741218447
0.06909596810117363,0.08813362354412675
0.06531133520882576,0.11605772119946778
0.07652723711915314,0.09117867266759276
0.07322509707883,0.09269627463072538
0.06975688884034753,0.1137715831398964
0.07155834899749607,0.10298831313848496
0.06897899566683918,0.09448405038565397
0.07318085938692093,0.10469248816370964
0.07400675541721284,0.09431774653494358
0.06931581133510917,0.10507752425037324
0.0784871042938903,0.09548222888261079
