training loss,validatation loss
0.00047295469110054,0.0003211000144705767
0.0003218361182149465,0.00018199593905592892
0.0002590251722216408,0.00016656166096664092
0.00018889901214492967,0.00014034950604804308
0.0002064803179439423,0.0003516736643256385
0.00020710265313653053,0.0003012192000278191
0.00020032118579308645,0.0003512569952952482
0.00022235663728380927,0.00018645652107711626
0.00020714805706077753,0.0004380391774304826
0.00021297908151666434,0.00019151753243704662
0.00019480005837522186,0.00018995267624575263
0.00017652703125207837,9.07546752671351e-05
0.00018410677833230693,0.00024166360229855855
0.00018525755060494475,7.751588832434208e-05
0.0002036798970198106,0.000312487455369137
0.000209866102014189,0.0002728925304552376
0.00019169452833651236,0.0003486414041901753
0.00020434263826615506,0.00044080861662507684
0.00015367604121479416,0.0003409908870978029
0.0001685809089713075,0.00017394255721683293
0.00017706182629126488,0.00022325700876990595
0.00018775362830965038,0.0002584447640415988
0.00017756018631786218,0.0003558611711213189
0.00021990900682752112,0.00014361680516969955
