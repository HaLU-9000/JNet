training loss,validatation loss
0.10546038582921029,0.5633004374802113
0.08811881870031357,0.09108502250164748
0.08470533777028322,0.09371058121323586
0.0830836277268827,0.10453477092087268
0.07922691599465907,0.0936531376093626
0.07679946513846517,0.08849596548825503
0.08028977646492422,0.08086703270673752
0.08312156924977898,0.08608097303658724
0.08626583859324455,0.08581143952906131
0.08003108617849648,0.07139459755271674
0.08416230560280383,0.0830229079350829
0.07739290176890791,0.08503847233951092
0.07449240946210921,0.06435029823333024
0.07303062975406646,0.07947650589048863
0.0773779518622905,0.07114935982972384
0.07833246869966387,0.08383703678846359
0.07211680395528675,0.0897658022120595
0.07424960999749601,0.07756003737449646
0.07175563065335154,0.06513667926192283
0.07831017729826271,0.08446785248816013
0.07200201927684248,0.06777576636523008
0.07109069492667913,0.07662595938891173
0.068546729600057,0.07935255207121372
0.0671456000674516,0.07768978793174028
0.06287040742114186,0.07417193427681923
0.06300501281861216,0.07058498021215201
0.062165969582274556,0.05828069355338812
0.06110408505424857,0.06438256911933422
0.06377458901144564,0.07788968160748481
0.05620949193835258,0.06592943463474513
0.05921177473384887,0.06057520117610693
0.06037339022383094,0.07290415465831757
0.058409010646864774,0.06896578483283519
0.0573157852049917,0.09007703708484768
0.05849418821744621,0.06645897720009089
