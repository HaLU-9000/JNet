training loss,validatation loss
0.0011280138523443383,0.00011077642822721997
0.0008099758039088556,9.388318285767638e-05
0.00042468592428122063,9.357288632116955e-05
0.00032104106153383325,6.633043093188463e-05
0.0002896731323562562,0.00013982108534719368
0.00028829489040617775,7.39159133468289e-05
0.00027609600094365307,7.555233328275792e-05
0.0002874777335455292,6.272582563951798e-05
0.00028428000641724795,0.00013498178863528666
0.000246074525257427,0.00011979930417737705
0.0002702026446058881,8.869626304090172e-05
0.0002772528191417223,8.709163327921491e-05
0.0002670636082257261,0.00011123564449235343
0.00025688021934911376,0.00011912970635307826
0.00023255941194292974,9.021540946889674e-05
0.00028917628349518055,0.00010073188478258999
0.0002531601008740836,0.00010050365691654403
0.0002655456231877906,0.00010673504069416139
0.0002772718688720488,0.00010797177943231868
0.00026872596490647995,0.0001081283926504284
0.00022611742271692493,0.00010233226460229614
0.00022137133606520365,0.00011361816835346872
0.00021577368868747727,9.878681253496782e-05
0.00022921528876395313,9.630290607319123e-05
0.0002293905965780141,0.00010366886765439179
0.0002389191302609106,0.00011885635656255998
0.0002554325231903931,9.539941514049135e-05
0.0002308071837069292,9.319975170853925e-05
