training loss,validatation loss
0.13393723038956523,0.10719254314899444
0.1167007178068161,0.19320696480572225
0.10810441058129072,0.09049621671438217
0.10520994206890463,0.09819757174700498
0.10484371447004377,0.08218262773007154
0.09952008983120322,0.08823708202689887
0.10119756617583335,0.07226459905505181
0.10078961114399135,0.08419844619929791
0.1029353235848248,0.08706878460943698
0.0942689477559179,0.08321350775659084
0.09718643619678914,0.07771292887628078
0.09516015595756472,0.07831023540347815
0.09070279759354889,0.07662663329392672
0.092470495053567,0.08033483605831862
0.09311694039031863,0.07225530724972487
0.08992142067290843,0.08063213434070349
0.08464748947881162,0.06689613126218319
0.09203962678089737,0.08087787888944149
0.08247405372560024,0.07529192753136157
0.07915781173855066,0.07816056031733751
0.08242635819595306,0.06758923586457968
0.08093108667992055,0.061378370970487595
0.07832410776056349,0.06308945547789335
0.07609186881221831,0.06476695500314236
0.06826550448313355,0.05716967172920704
0.07001421723980457,0.06133444234728813
0.06965849857777356,0.0620649877935648
0.06814363765530289,0.06070619635283947
0.07278191134799272,0.05765768196433783
0.06550865036435426,0.061936278641223905
0.06679197778459639,0.06403014920651913
0.06313358061946929,0.05984337944537401
0.0651280152099207,0.06468993593007326
0.06761495304293931,0.05734405163675547
0.06522760335355997,0.05778476111590862
0.06629634272772819,0.056243759393692014
0.064101593028754,0.06537690125405789
0.06529439647682012,0.06309716310352087
0.06380758307874203,0.056525775045156476
0.06438909706193954,0.06065922323614359
0.06559124461840839,0.06224044989794493
0.06660657403059304,0.06008343081921339
0.06706400162540377,0.07489667180925608
0.06771591537166387,0.06693582888692617
0.06648913321085274,0.06782347410917282
0.0667103428952396,0.07049641013145447
