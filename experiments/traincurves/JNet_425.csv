training loss,validatation loss
0.0013360367965242403,0.0008858694306436377
0.0007564191031588052,0.0005845185238883635
0.0003330452215095647,0.0003473413592066982
0.00028938838491967547,0.00033046053770249275
0.0003099386607800625,0.0003331363405322918
0.0002349985609725991,0.00018729095318121837
0.0002074525877264932,0.0002087282292677628
0.0002100569244998951,0.0003269393531354581
0.00023176898262931899,0.00026429351314618545
0.0002255579831785326,0.0001450567219990262
0.000216644983655101,0.00010028728950430831
0.00018804239997479043,0.004952026575301716
0.00018230267004426537,0.00027317821361521054
0.00017241238403016722,0.00016975851149538811
0.00016898371296406367,0.0002917517165201389
0.00019000100906254146,0.00011253484682356429
0.00021810843644175292,0.00014947285449125048
0.00016967288942851155,0.00026993430292066023
0.00017626196246197878,5.911771850151126e-05
0.00018099582362282262,0.0001593193106941726
0.00019175690072785302,0.0003297256842586194
0.00017788219466837062,0.00029122438916431295
0.00017503094182103496,0.001397516582727576
0.00018375334885689654,0.00020555306190885858
0.0001790355851025538,0.00016687253616680663
0.00015462861623205982,0.0004707284630853792
0.000186852388553973,9.224914708454435e-05
0.0001618607177101694,0.00015676429138693492
0.00019045990932426094,0.00016313803048433327
