training loss,validatation loss
0.11034038374200464,0.11237722411751747
0.0893698145262897,0.11014232598245144
0.09576132228597999,0.09140343107283115
0.08698918556794524,0.10096994638442994
0.08350109911523759,0.09750481639057398
0.0825921995099634,0.0809192081913352
0.08075580830685794,0.07978616338223218
0.08635404467582702,0.07229711040854454
0.0808281528018415,0.07198544181883335
0.06996415357105434,0.07844758033752441
0.07698234247975051,0.08931610360741615
0.06996160311624408,0.07194674611091614
0.06807706882245838,0.0743044838309288
0.06035806717351079,0.07768538305535913
0.05687002446502447,0.06659377086907625
0.05901085297577083,0.06716574802994728
0.05563807412981987,0.06429673284292221
0.05167144491802901,0.06851349212229252
0.050275769741274415,0.06931462734937668
0.04446015357971191,0.07727141305804253
0.04560967813245952,0.067600620072335
0.04616168229840696,0.07384432777762413
0.046612103674560784,0.058688068948686126
0.045471877031959596,0.07279562652111053
0.045747265433892605,0.06825237022712827
0.045556004690006376,0.057960689440369605
0.04612472159788013,0.05965363085269928
0.04592050408013165,0.06546547748148442
0.04505333314184099,0.08356144931167364
0.043913196753710505,0.07485590651631355
0.04180449822451919,0.06516155144199728
0.046805271790362896,0.07030079867690801
0.04403578011319041,0.06899860072880984
0.04505441010929644,0.06436785375699401
0.04386835576966405,0.08580400384962558
0.04446439100895077,0.06424887161701917
0.04400233714375645,0.07347632329910994
0.04190856993198395,0.060855976212769745
0.04628607369959355,0.08510650238022208
0.04477098610717803,0.07218333818018437
0.043569623618386684,0.06226485129445791
0.04413840787950903,0.06728155799210071
0.044981820303946735,0.08011241182684899
0.045271594757214186,0.07664981670677662
