training loss,validatation loss
0.6560004022717476,0.6888694107532501
0.6328076541423797,0.6438428729772567
0.630591838657856,0.6394887566566467
0.6365901520848274,0.6800468683242797
0.6332590594887734,0.6428076535463333
0.6244447815418244,0.652847844362259
0.6267521438002587,0.655860823392868
0.6219339135289192,0.6660187482833863
0.6232589676976203,0.6888759285211563
0.6225677520036698,0.6663458436727524
0.6209192612767219,0.6710714280605317
0.6209466904401779,0.6513279229402542
0.6236068338155747,0.6443699061870575
0.6217224365472793,0.6553699254989624
0.6252498015761375,0.6451276212930679
0.621572585105896,0.6348325669765472
0.6202035138010978,0.6396562218666076
0.6177116987109185,0.6376575320959091
0.6180716750025749,0.6359675198793411
0.6190962412953377,0.6343510150909424
0.6181133395433426,0.6439563155174255
0.6195301687717438,0.6371949940919877
0.6192643830180168,0.6375915855169296
0.6201473492383957,0.6391904860734939
0.6191022863984108,0.6409528881311417
0.6195382708311081,0.6392158210277558
0.619270450770855,0.6444566041231156
0.6213945996761322,0.6429920464754104
0.620199765264988,0.6433521866798401
0.6207781422138214,0.6421819150447845
0.6211698621511459,0.640606552362442
0.6203310865163804,0.6441280037164688
0.6200039261579513,0.6441124141216278
