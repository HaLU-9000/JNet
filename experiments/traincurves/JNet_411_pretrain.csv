training loss,validatation loss
0.1335853657312691,0.18419671282172204
0.11589999364688992,0.13627203851938247
0.11232189627364278,0.11489062756299973
0.09758700897917151,0.11299443058669567
0.10145197756588459,0.1248314306139946
0.10443109644576908,0.11662951782345772
0.10491570817306638,0.09462433308362961
0.09463355645537376,0.1052441157400608
0.0938194528594613,0.10554147642105818
0.09691847286187112,0.10034151859581471
0.0910472427867353,0.09497939497232437
0.0895521715655923,0.10881522167474031
0.0839174764789641,0.08870032653212548
0.08635875286534428,0.08294585235416889
0.08356875259429217,0.07229204177856445
0.08049915467388928,0.08729996532201767
0.07812147761695087,0.09194313120096922
0.07883377426303922,0.09578219689428806
0.08026497057639062,0.08278527185320854
0.07926537935622037,0.07775251604616643
0.07573925447650254,0.08797386605292559
0.07158936347812414,0.07367258463054896
0.07278434798121453,0.07227528616786003
0.07282164158299566,0.0820788161829114
0.07034438416361809,0.08563964907079935
0.07143618819303811,0.07516202442348004
0.06995447529479862,0.0824932362884283
0.07010157543234527,0.08830108530819417
0.07286044406704605,0.08219461310654878
0.07033532176166774,0.0832258841022849
0.06676944738253951,0.09304038267582655
0.07238871886394918,0.08242417573928833
0.07066722967661918,0.0968519052490592
0.07136299655772746,0.07569062430411577
0.07107493857853114,0.08439964037388563
0.07191161743365228,0.10015044640749693
0.07204184221103788,0.08172471672296525
0.07050383559428156,0.08774304091930389
0.07184168516658246,0.07893159221857786
0.06857489245012402,0.08121853079646826
0.06737157561816275,0.08872583042830229
0.06907844495028258,0.08070824341848493
0.06974531410261989,0.08674832489341497
0.06831778003834188,0.08601070307195187
0.06901300767436623,0.08225607946515083
0.06938201287761331,0.08343113102018833
0.06948900472372771,0.08785203732550144
0.07084539568051695,0.08244997765868903
0.06741337716579437,0.07442229948937892
