training loss,validatation loss
0.136117287799716,0.1474300678819418
0.12193517023697495,0.12321496866643429
0.1151877603493631,0.11736137121915817
0.11097224092110991,0.11416244693100452
0.10197751386091113,0.12111668027937413
0.1087423644028604,0.10413233600556851
0.10874558260664344,0.11211857385933399
0.101698091737926,0.09514033570885658
0.10150506260804831,0.09357890281826257
0.10018881309777498,0.09310750253498554
0.09370036412030458,0.09928502812981606
0.09352184277959168,0.09937855191528797
0.09465026011690497,0.09138485044240952
0.09153684922493995,0.10345030911266803
0.09015502863563597,0.08952041156589985
0.0892263909522444,0.09240273367613554
0.08113983417861163,0.09490254204720258
0.08466496453620494,0.10100659243762493
0.08609467834234237,0.0786944916471839
0.0900615724734962,0.09057654663920403
0.08177425040863455,0.08171409722417593
0.07865762854926288,0.09541841950267553
0.07727570522576571,0.08086020536720753
0.07499124658294022,0.08765728641301393
0.07548030578531324,0.07900346759706736
0.07727173363789916,0.0961514551192522
0.07677409413270653,0.0812985060736537
0.0706288408441469,0.09674601256847382
0.07474815901368856,0.08061795961111784
0.07712145110592246,0.08129530288279056
0.07448078799061478,0.08596341069787741
0.07375721450895072,0.09324306603521108
0.07423952720127999,0.0865699851885438
0.0752997687831521,0.08347845934331417
0.07512576487846673,0.08827660027891397
