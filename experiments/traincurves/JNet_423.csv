training loss,validatation loss
0.0005998168270889436,0.0008546973804347145
0.000272634042989921,0.003134356081861328
0.00022748780643723875,0.0027660670903024557
0.00021923255585306833,0.0012415803854633031
0.0001947219023566049,0.002826128714208293
0.0002232105970495013,0.0004898086709404433
0.00022112288766834354,0.00044329924531797473
0.00021171946548520282,0.0004131263009810486
0.00018250752009976167,0.000926811192198484
0.0002590134287129331,0.0002101196984398257
0.0002299640546613091,0.00020185116294442197
0.0001932517284495816,0.0003322276996442497
0.00016954777117845766,0.00020535364346585538
0.00016464236166328306,0.0001857148854071511
0.00019285947297987605,0.00012983369952621616
0.00015277035056342924,0.00015749444866912653
0.00017526337336931874,0.00018871259001684848
0.00018707840794888854,0.00012484066734828048
0.00015481884567037697,0.00017559137805847058
0.00017824980202249207,0.0001170697857929781
0.00017175559197795564,0.00016503693632330396
0.00018543991768922298,0.00014640661852922677
0.0001819328115337271,0.00011366422302216961
0.00016933572507667804,7.5716749583421e-05
0.00016644202900607753,0.00016874455622541972
0.00012824172096372876,0.00016605898024408817
0.00016512125526446653,0.00011645171031204882
0.00015775824968670805,0.00022217976585352516
0.00017475252881851588,0.00018477324223482584
0.00015388927082824467,0.00011385455089225615
0.00012628161175570084,6.565202822343963e-05
0.0001579292619837247,5.5647076730735987e-05
0.00015600075798133161,0.000133879601636977
0.00012702574097232854,0.0001617683447221907
0.00015265017461700835,0.00017759525110250252
0.00012706916673835167,0.00018887282042214792
0.0001292884742690603,0.0001270317037466384
0.00013747846285085076,7.913407469857247e-05
0.00012959846956931643,0.00019859103236683496
0.0001482726149923508,0.00011700227294113575
0.00015047444549026067,0.00019412224509096632
0.0001297042718564967,0.00013139318707509063
