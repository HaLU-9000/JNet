training loss,validatation loss
0.1481516232341528,0.1515175711363554
0.11778513748198748,0.13122236616909505
0.11261296281591057,0.12257715724408627
0.11271057078614831,0.12313527651131154
0.10839092480018735,0.12552539743483065
0.10276549987494946,0.10611948017030955
0.1040155223943293,0.12556594386696815
0.09937129588797688,0.1042790286242962
0.09300781341269612,0.101006293669343
0.09068419758230448,0.09753581546247006
0.09252769282087683,0.10043949112296105
0.09342013916000724,0.10848668739199638
0.08869870944879948,0.08866357374936343
0.09224731280468404,0.09099510423839093
0.09231592998839915,0.10625024624168873
0.08986217329278588,0.08812496494501829
0.08191531499847769,0.08394080866128206
0.08540836021304131,0.08534979149699211
0.07556601258926093,0.07494050692766904
0.07817915851250291,0.09336519762873649
0.08555608600378037,0.08620122075080872
0.07918170561082662,0.09036581590771675
0.08403625727631152,0.1021124318242073
0.07539822292514145,0.10252327956259251
0.07617685658857226,0.09100903905928134
0.0769252180494368,0.08514977041631937
0.07488201661966741,0.08697663098573685
0.07628436405211687,0.09290553368628025
0.07326539730653167,0.11077383533120155
0.07480510273948311,0.09873501099646091
0.0735126815084368,0.09744939412921667
0.07277433750219643,0.08978802412748337
0.07174139288254082,0.0888643778860569
0.06988923606462777,0.10782006345689296
0.07388000281527639,0.10631684064865113
0.06909868854563683,0.10721748322248459
0.07060040157288312,0.10596622303128242
0.06910466212779283,0.08731448333710431
0.06654012004844845,0.10267840661108493
0.0750030403956771,0.10310647692531347
0.0699687190912664,0.0903663169592619
0.07135786920785904,0.10631681941449642
0.06674223272129894,0.09741547331213951
0.06832511421293021,0.10358145106583834
0.07052737756632269,0.11875137686729431
2.8102485829684882,3.461361062526703
